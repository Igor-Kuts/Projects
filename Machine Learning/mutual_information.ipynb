{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15711aa5-8158-4f84-a84c-fe39b6190382",
   "metadata": {},
   "source": [
    "# Mutual Information\n",
    "\n",
    "## Overview:\n",
    "**Mutual Information (MI)** is a concept from *Information Theory* that measures the amount of information that is shared between two random variables. <u>Mutual Information quantifies the degree to which knowledge of one variable reduces uncertainty about another variable</u>. In simpler terms, Mutual Information tells us how much knowing the value of one variable helps us predict the value of another variable.\n",
    "\n",
    "<span style=\"font-size: 11pt; color: steelblue; font-weight: bold\">Mutual Information is crucial in Machine Learning for feature selection, dimensionality reduction, and building effective models.</span> \n",
    "- <span style=\"font-size: 11pt; color: mediumseagreen; font-weight: bold\">It helps in identifying the most informative features that contribute to predictive accuracy.</span>\n",
    "\n",
    "***\n",
    "Mutual Information was first introduced by <span style=\"font-size: 14pt; color: goldenrod; font-weight: bold\">Claude Shannon</span>, the father of information theory, in his landmark paper \"*A Mathematical Theory of Communication*\" published in 1948. It has since become a fundamental concept in various fields including statistics, information theory, machine learning, and more.\n",
    "***\n",
    "\n",
    "## Things to note:\n",
    "- MI can be used to detect dependencies or relationships between variables, but <span style=\"font-size: 11pt; color: orange; font-weight: bold\">MI doesn't imply causation</span>. Correlation does not necessarily imply causation.\n",
    "- <span style=\"font-size: 11pt; color: orange; font-weight: bold\">MI is sensitive to the scales and ranges of variables</span>. Preprocessing and normalization may be necessary.\n",
    "- MI assumes discrete variables, but it can be approximated for continuous variables using discretization techniques.\n",
    "- <span style=\"font-size: 11pt; color: orange; font-weight: bold\">MI might not capture more complex relationships</span> between variables that other measures like conditional mutual information or non-linear correlations could capture.\n",
    "\n",
    "## Formulas:\n",
    "The Mutual Information between two discrete random variables X and Y is typically denoted as MI(X; Y) and is calculated using the following formula:\n",
    "\n",
    "$$\\large MI(X; Y) = \\sum_{x \\in X} \\sum_{y \\in Y} p(x, y) \\log\\left(\\frac{p(x, y)}{p(x) \\cdot p(y)}\\right) $$\n",
    "\n",
    "Where:\n",
    "- $p(x, y)$ is the joint PMF of X and Y.\n",
    "- $p(x)$ and $p(y)$ are the marginal PMFs of X and Y respectively.\n",
    "- The logarithm is usually taken to the base 2 or the natural logarithm.\n",
    "\n",
    "## Interpreting MI values:\n",
    "Understanding the values of Mutual Information and their implications can provide insights into the relationships between variables. The range of MI values can vary based on the characteristics of the data and the relationship between the variables.\n",
    "\n",
    "- **MI = 0**: This indicates that the variables are independent; knowing one provides no information about the other.\n",
    "- **MI > 0**: Positive MI values indicate some level of dependence or association between the variables. The higher the MI value, the stronger the association.\n",
    "- **MI < 0**: Negative MI values are less common and suggest that knowing one variable reduces uncertainty about the other more than expected if they were independent. However, such negative values might be due to noise or data artifacts.\n",
    "\n",
    "For binary features MI values falls in the range $[0,1]$, where 0 corresponds to complete independence and 1 - for perfect dependence.\n",
    "\n",
    "## Applications:\n",
    "Mutual Information has various use cases across different fields, including, but not limited to:\n",
    "- **Feature Selection**: MI can be used to select relevant features in machine learning by measuring the amount of information that a feature provides about the target variable.\n",
    "- **Clustering**: MI can help in determining the similarity between clusters in unsupervised learning.\n",
    "- **Natural Language Processing**: It's used to measure the relationship between words in text corpora.\n",
    "- **Information Retrieval**: It's used to measure the similarity between documents and query terms in information retrieval systems.\n",
    "- **Image Registration**: In medical imaging, MI can be used to align and register images from different modalities.\n",
    "- **Neuroscience**: It's used to measure the relationship between neural activities and stimuli.\n",
    "- **Bioinformatics**: MI is used in genetics to understand the relationships between different genetic markers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cabe83-2317-4fa9-9604-305e2e576bee",
   "metadata": {},
   "source": [
    "# Worked Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfdddc0-7c1b-418e-b4f1-7af8a9e45305",
   "metadata": {},
   "source": [
    "#### Manual computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c7f020-47a6-40a8-bdba-a9845b407e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3651d5e-06b8-4d98-8c4d-d36b11cd5eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drinks_soda</th>\n",
       "      <th>eats_fastfood</th>\n",
       "      <th>does_sports</th>\n",
       "      <th>is_overweight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>James</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Michael</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>David</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>John</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robert</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>William</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Benjamin</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Christopher</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             drinks_soda  eats_fastfood  does_sports  is_overweight\n",
       "James                  0              1            0              1\n",
       "Michael                1              0            0              0\n",
       "David                  0              1            1              0\n",
       "John                   0              1            0              1\n",
       "Robert                 1              0            0              0\n",
       "William                0              0            1              0\n",
       "Benjamin               1              1            0              1\n",
       "Christopher            1              0            0              0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Where '0' stands for 'no' and '1' stands for 'yes'\n",
    "index = [\"James\", \"Michael\", \"David\", \"John\", \"Robert\", \"William\", \"Benjamin\", \"Christopher\"]\n",
    "cols = {'drinks_soda':   [0,1,0,0,1,0,1,1],\n",
    "        'eats_fastfood': [1,0,1,1,0,0,1,0],\n",
    "        'does_sports':   [0,0,1,0,0,1,0,0],\n",
    "        'is_overweight': [1,0,0,1,0,0,1,0]}\n",
    "\n",
    "df = pd.DataFrame(cols, index=index)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64852cd5-f38b-46c0-b578-295fca2fe894",
   "metadata": {},
   "source": [
    "Now let us calculate the Mutual Information between features `'eats_fastfood'` and target variable `'is_overweight'`.   \n",
    "In other words, let's find out how much knowing if the person eats fastfood or not helps us in predicting him being overweight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efccdd18-e86c-4f6e-9967-f5efc5fd96cb",
   "metadata": {},
   "source": [
    "First, lets, compute marginal probabilities of `'eats_fastfood'` and `'is_overweight'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5fb64ad-bed4-4140-b182-7c8ad8cf8abe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marginal PMF for \"eats_fastfood\" = 1: 0.5\n",
      "Marginal PMF for \"is_overweight\" = 1: 0.375\n"
     ]
    }
   ],
   "source": [
    "# out of 8 people, 4 of them eat fastfood, so\n",
    "marginal_pmf_eats_fastfood = 4/8 \n",
    "\n",
    "# out of 8 people, 3 of them are overweight, so\n",
    "marginal_pmf_is_overweight = 3/8\n",
    "\n",
    "print(f'Marginal PMF for \"eats_fastfood\" = 1: {marginal_pmf_eats_fastfood}')\n",
    "print(f'Marginal PMF for \"is_overweight\" = 1: {marginal_pmf_is_overweight}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771fd45d-cb31-4850-ba0b-253bbf04a9dc",
   "metadata": {},
   "source": [
    "Second, we compute joint PMFs for `'eats_fastfood'` and `'is_overweight'`.  \n",
    "In total we will have to compute 4 joint PMFs:\n",
    "1. eats_fastfood = 'yes' and is_overweight = 'yes'\n",
    "2. eats_fastfood = 'yes' and is_overweight = 'no'\n",
    "3. eats_fastfood = 'no' and is_overweight = 'yes'\n",
    "4. eats_fastfood = 'no' and is_overweight = 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e877e0-2d62-4fd7-95d8-010124b9132b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joint probability: eats_fastfood = \"yes\" and is_overweight = \"yes\" = 0.375\n",
      "Joint probability: eats_fastfood = \"yes\" and is_overweight = \"no\" = 0.125\n",
      "Joint probability: eats_fastfood = \"no\" and is_overweight = \"yes\" = 0.0\n",
      "Joint probability: eats_fastfood = \"no\" and is_overweight = \"no\" = 0.375\n"
     ]
    }
   ],
   "source": [
    "# eats_fastfood = 'yes' and is_overweight = 'yes'\n",
    "pmf_yes_yes = 3/8\n",
    "print(f'Joint probability: eats_fastfood = \"yes\" and is_overweight = \"yes\" = {pmf_yes_yes}')\n",
    "\n",
    "# eats_fastfood = 'yes' and is_overweight = 'no'\n",
    "pmf_yes_no = 1/8\n",
    "print(f'Joint probability: eats_fastfood = \"yes\" and is_overweight = \"no\" = {pmf_yes_no}')\n",
    "\n",
    "# eats_fastfood = 'no' and is_overweight = 'yes'\n",
    "pmf_no_yes = 0/8\n",
    "print(f'Joint probability: eats_fastfood = \"no\" and is_overweight = \"yes\" = {pmf_no_yes}')\n",
    "\n",
    "# eats_fastfood = 'no' and is_overweight = 'no'\n",
    "pmf_no_no = 3/8\n",
    "print(f'Joint probability: eats_fastfood = \"no\" and is_overweight = \"no\" = {pmf_no_no}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86a62e9-d98b-49c2-a57d-cae09f44f7f8",
   "metadata": {},
   "source": [
    "Now we plug in the numbers into Mutual Information formula:\n",
    "\n",
    "$$\\large MI(X; Y) = \\sum_{x \\in X} \\sum_{y \\in Y} p(x, y) \\log\\left(\\frac{p(x, y)}{p(x) \\cdot p(y)}\\right) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13097a1-05a4-4ffc-9894-105fe09fc2e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information coefficient between \"eats_fastfood\" and \"is_overweight\" = 0.3083968903267524\n"
     ]
    }
   ],
   "source": [
    "# Note that we are using logarithm of base 2\n",
    "# Third term: 0.000 * np.log2(0.000 / (0.5 * 0.375)) is ignored since log2(0) is undefined\n",
    "MI = 0.375 * np.log2(0.375 / (0.5 * 0.375)) + \\\n",
    "     0.125 * np.log2(0.125 / (0.5 * 0.625)) + \\\n",
    "     0.375 * np.log2(0.375 / (0.5 * 0.625))\n",
    "\n",
    "print(f'Mutual Information coefficient between \"eats_fastfood\" and \"is_overweight\" = {MI}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50491ceb-e1f7-4120-b791-72e2fcf6a569",
   "metadata": {},
   "source": [
    "So the Mutual Information coefficient between 2 examined variables is strongly positive, which suggests that knowing the value of `'eats_fastfood'` feature might provide significant insights into the target variable.  \n",
    "\n",
    "Since for binary features MI takes values in the range $[0,1]$:  \n",
    "`'eats_fastfood'` posesses moderate predictive power for determining if the person is overweight or not. Target variable `'is_overweight'` moderately depends on the feature '`eats_fastfood`'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd696fe-e570-475b-a49f-94200cf4f603",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Via Sci-Kit Learn's `mutual_info_score`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d974be97-fcf6-4c90-b696-589c918c2423",
   "metadata": {},
   "source": [
    "Identical result can be (**and must be**) achieved in just one line of code with the help of Sci-Kit learn library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb9edb46-73f2-4947-b996-ce5a4d1f3117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information: 0.38039566584857787\n"
     ]
    }
   ],
   "source": [
    "mi_score = mutual_info_score(df['eats_fastfood'], df['is_overweight'])\n",
    "print(\"Mutual Information:\", mi_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c2d352-a93e-45c7-80c2-280261c5c3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
