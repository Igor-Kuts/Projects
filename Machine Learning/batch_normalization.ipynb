{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f724b4f-b772-44b1-b629-229728fe6c29",
   "metadata": {},
   "source": [
    "# Batch Normalization (BatchNorm)\n",
    "\n",
    "### Overview:\n",
    "Batch Normalization (BatchNorm) is a technique commonly employed during training of Deep Neural Networks (DNNs). It addresses the issue of *internal covariate shift*, which is the change in the distribution of network activations during training. BatchNorm aims to stabilize and accelerate the training process by normalizing the inputs of each layer in a mini-batch.\n",
    "\n",
    "Batch Normalization helps to address the unstable gradients problem while also making the network train a little bit faster. At the same time BatchNorm helps dealing with overfitting by having a slight regularization effect on the network during training.\n",
    "***\n",
    "BatchNorm was introduced by **Sergey Ioffe** and **Christian Szegedy** in their paper [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    " in 2015.  It was initially proposed to address the challenges of training very deep Neural Networks.\n",
    "***\n",
    "\n",
    "#### Internal Covariate Shift:\n",
    "\n",
    "- **Covariate Shift:** In the context of Machine Learning and Neural Networks, <u>covariate shift refers to the change in the distribution of input data between training and testing phases</u>. When the distribution of the training data differs significantly from the distribution of the testing data, it can lead to decreased model performance.\n",
    "\n",
    "- **Internal Covariate Shift:** Internal covariate shift <u>extends this idea to the distribution of the activations within a neural network's layers during training</u>. As we train a DNN, the distribution of activations (output values) within each layer tends to change as the model's parameters are updated. This shift in the distribution of activations is known as internal covariate shift.\n",
    "\n",
    "- **Impact on Training:** Internal covariate shift can pose challenges during training for a couple of reasons:\n",
    "\n",
    "    - Vanishing/Exploding Gradients: When the distribution of activations changes dramatically, it can lead to issues like vanishing or exploding gradients. These issues hinder the convergence of the optimization algorithm and slow down the training process.\n",
    "\n",
    "    - Learning Rate Sensitivity: If the distribution shifts significantly, certain layers might require very small learning rates to prevent the network from diverging during training. This slows down the overall learning process.\n",
    "\n",
    "### Explanation:\n",
    "During the training of a neural network, the distribution of inputs to each layer can shift due to changing parameters in previous layers. This can slow down training as the network needs to continuously adapt to these shifts. BatchNorm counters this by ensuring that the inputs to a layer have a consistent mean and variance.\n",
    "\n",
    "BatchNorm operates within a mini-batch of training examples. For each feature in the mini-batch, it calculates the mean and variance, normalizes the features based on these statistics and then also scales and shifts the data using learnable parameters $\\gamma \\text{ (gamma)}$ and $\\beta \\text{ (beta)}$. \n",
    "\n",
    "### Formulas:\n",
    "Batch Normalization is performed using the following formulas:   \n",
    "\n",
    "For a feature $x$ in a mini-batch, the BatchNorm transformation is applied as follows:\n",
    "$x$\n",
    "1. Calculate the mean $\\mu$ and variance $\\sigma^2$ of the feature across the mini-batch.\n",
    "2. Normalize the feature: $\\large \\hat{x} = \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$, where $\\epsilon$ is a small constant to avoid division by zero.\n",
    "3. Scale and shift the normalized feature using learnable parameters: $\\large z^{(i)} = \\gamma \\odot \\hat{x}^{(i)} + \\beta$, where $\\gamma \\text{ (gamma)}$ is the scaling parameter and $\\beta \\text{ (beta)}$ is the shifting (offset) parameter.\n",
    "\n",
    "### Implementation Details:\n",
    "- **Poor perfomance for very small batches:** Because BatchNorm computes statistics for normalizing data over each separate feature in the mini-batch, it might not work as well for small batches – 16 or so.\n",
    "- **Learnable $\\gamma$ and $\\beta$:** Learnable means that we don't have to specify them during model creation. Their values will be learned by the network during training.\n",
    "- **$\\beta \\text{ (beta)}$ vs Bias $b$:** Beta learnable parameter is used in the same way as bias to offset the data, so in the end we don't need both of them if we are using BatchNorm, as they both serve the same purpose. When using BatchNorm we can train our network without the bias hyperparameter, thus making the training sligly faster and less complicated.\n",
    "```python\n",
    "# We can use beta from BatchNorm\n",
    "# instead of bias in a layer.\n",
    "model = keras.models.Sequential ([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation = 'relu', use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    ...\n",
    "```\n",
    "- **Sligtly longer Epochs:** With Batch Normalization each epoch will take slightly longer, due to addition computational overhead from transformations and learnable parameters, but convergence will be faster and more accurate.\n",
    "- **Normalizing Input Data:** With Batch Normalization we can <u>add additional BatchNorm layer before our first input layer</u> in the model architecture <u>to effectively normalize the input data prior to training</u>, thus removing the need for separate data normalization prior to feeding it to the network.\n",
    "```python\n",
    "# Adding BatchNorm layer after Flatten layer, \n",
    "# before the first Dense layer.\n",
    "model = keras.models.Sequential ([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation = 'relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    ...\n",
    "```\n",
    "- **Slight Regularization effect:** Batch Normalization can have a slight normalization effect on the network training process, due to it computing mini-batch statistics based on the relatively small amount of mini-batch data, thus adding some additional noice.\n",
    "    - **Note:** Amount of regularition effect depends on the size of mini-batch, – the bigger the batches, the less the regularization effect.\n",
    "    - **Note:** Regularization effect of BatchNorm must not be treated as the main source of regularization for the network! The only correct way to view it is as an additional benefit, but not the main purpose of BatchNorm. We still have to employ traditional regularization techniques to negate overfitting, like Dropout layers and Regularization layers.\n",
    "- **BatchNorm before the Activation function:** Authors of the original article spoke favourably of applying BatchNorm before applying activation function, but this is the thing we must test on our own, if it is beneficial for the network or not. Some people argue that it is.\n",
    "```python\n",
    "# Adding BatchNorm layer before activation function\n",
    "model = keras.models.Sequential ([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300)\n",
    "    keras.layers.BatchNormalization(),\n",
    "    # Apply ReLU activation after BatchNorm\n",
    "    keras.layers.Activation('relu')\n",
    "    ...\n",
    "```\n",
    "### Code Examples:\n",
    "Simplified example of how BatchNorm might be implemented in a neural network in TensorFlow:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assume `input_data` is the input to a layer\n",
    "normalized_data = tf.keras.layers.BatchNormalization()(input_data)\n",
    "```\n",
    "And PyTorch:\n",
    "```python\n",
    "import torch.nn as nn\n",
    "\n",
    "def __init__(self):\n",
    "    super(SimpleNN, self).__init__()\n",
    "\n",
    "    self.fc1 = nn.Linear(in_features=784, out_features=256)\n",
    "    self.bn1 = nn.BatchNorm1d(num_features=256)\n",
    "```\n",
    "- BatchNorm was initially designed for convolutional and fully connected layers, but its concepts have been extended to other architectures.\n",
    "- It has been influential in the design of subsequent normalization techniques like Layer Normalization and Group Normalization.\n",
    "\n",
    "### Conclusion:\n",
    "Batch Normalization is a crucial tool for improving the training of Deep Neural Networks. It contributes to faster convergence, better generalization, and more stable training dynamics. Understanding how BatchNorm works and when to apply it can significantly enhance our ability to design and train effective machine learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
