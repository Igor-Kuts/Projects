{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf88bacd-2e9d-4a81-995c-626cbf998a93",
   "metadata": {},
   "source": [
    "# Mean Squared Error (MSE) Loss\n",
    "\n",
    "**Mean Squared Error** is a widely used loss function, <u>particularly in regression tasks</u>, where the goal is to predict continuous numerical values.  \n",
    "\n",
    "*It measures the average squared difference between the predicted values and the actual values*.\n",
    "\n",
    "The MSE loss is calculated by taking the average of the squared differences between each predicted value and its corresponding actual value. The formula for MSE is as follows:\n",
    "\n",
    "$$MSE = \\frac{1}{N}\\sum_{i=1}^{N}(y_{i} - \\hat{y}_{i})^2$$\n",
    "\n",
    "In this formula, $N$ represents the total number of samples, $y_{i}$ is the actual value, and $\\hat{y}_{i}$ is the predicted value.\n",
    "\n",
    "The MSE loss quantifies the overall average squared difference between the predicted values and the true values. By minimizing this loss, the model aims to reduce the discrepancy between its predictions and the actual values.\n",
    "\n",
    "\n",
    "\n",
    "### Some additional insights on the Mean Squared Error:\n",
    "\n",
    "1. **Squared Differences**: MSE calculates the average of the squared differences between predicted values and actual values. By squaring the differences, MSE places a higher weight on larger errors, <span style=\"font-size: 11pt; color: orange; font-weight: normal\">making it sensitive to outliers.</span>\n",
    "\n",
    "2. **Differentiability**: <span style=\"font-size: 11pt; color: green; font-weight: normal\">MSE is a differentiable loss function, which means it has a smooth and continuous derivative</span>. This property is crucial for optimization algorithms that rely on gradient-based methods, such as backpropagation, to update the model's parameters during training.\n",
    "\n",
    "3. **Non-Negative Values**: The MSE loss is always non-negative since it involves squared differences. A value of 0 indicates a perfect match between the predicted and actual values.\n",
    "\n",
    "4. **Units of Measurement**: The <span style=\"font-size: 11pt; color: orange; font-weight: normal\">units of MSE are the square of the units of the target variable.</span> For example, if the target variable represents distances in meters, the MSE loss will be expressed in square meters. This can make the interpretation of the loss function challenging when the units differ significantly from the original target variable.\n",
    "\n",
    "5. **Scale Sensitivity**: <span style=\"font-size: 11pt; color: orange; font-weight: normal\">MSE is sensitive to the scale of the data</span>. Variables with larger magnitudes can dominate the loss calculation, potentially affecting the training process. It is often recommended to scale the input features to a similar range to mitigate this issue.\n",
    "\n",
    "```\n",
    "These examples illustrate how MSE is sensitive to outliers.  \n",
    "\n",
    "Even a single outlier that deviates greatly from the true values can significantly affect the MSE. Squaring the differences in the calculation amplifies the impact of outliers, as the squared differences contribute more to the overall error. Consequently, the MSE is skewed by the presence of outliers, making it a less robust metric when dealing with data containing extreme values.\n",
    "```\n",
    "```python\n",
    "y_true = [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
    "y_pred = [90, 90, 90, 90, 90, 100, 100, 100, 100, 100]\n",
    ">>> MSE = 50\n",
    "\n",
    "y_true = [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
    "y_pred = [50, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
    ">>> MSE = 250\n",
    "\n",
    "```\n",
    "6. **Application to Regression**: MSE is commonly used as an evaluation metric and a loss function for regression tasks. By minimizing MSE during training, the model learns to minimize the average squared difference between its predictions and the true values, resulting in a model that performs well in terms of minimizing overall error.\n",
    "\n",
    "7. **Comparing Models**: MSE allows for easy comparison of different models. Lower MSE values indicate better performance, as they indicate smaller prediction errors on average.\n",
    "\n",
    "It's worth noting that while MSE has several advantages, it may not always be the most appropriate loss function for all scenarios. Depending on the specific characteristics of the problem, other loss functions, such as MAE (Mean Absolute Error) or custom loss functions, might be more suitable.\n",
    "\n",
    "**Below we will use three different methods to compute Mean Squared Error and compare the results**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fba54e-469b-425d-91df-6d877df24ffc",
   "metadata": {},
   "source": [
    "### Importing libraries and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c0cecca-29d3-429d-9ab9-60e59a3dca0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60f2f69a-752b-47cc-8577-ef852230970e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulated true values and predicted values\n",
    "\n",
    "# For PyTorch\n",
    "y_true_torch = torch.tensor([100, 100, 100, 100, 100, 100, 100, 100, 100, 100], dtype=torch.float32)\n",
    "y_pred_torch = torch.tensor([80, 100, 90, 95, 105, 101, 110, 99, 87, 100], dtype=torch.float32)\n",
    "\n",
    "# For SkLearn and Numpy\n",
    "y_true = [100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n",
    "y_pred = [80, 100, 90, 95, 105, 101, 110, 99, 87, 100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b9b4ee-25a8-4909-8ce3-a9d146dbac63",
   "metadata": {},
   "source": [
    "### Compute Mean Squared Error Loss with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d30386a-960e-4b78-96e3-cd6053ee9b4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Loss: 82.1\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of MSELoss\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "# Use it to compute MSE\n",
    "torch_mse = mse_loss(y_true_torch, y_pred_torch).item()\n",
    "\n",
    "# Round the result to 1 decimal number\n",
    "torch_mse = round(torch_mse, 1)\n",
    "\n",
    "print('Mean Squared Error Loss:', torch_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b3bc8-92bb-4936-8f3d-a28150688666",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute Mean Squared Error Loss with SciKit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d312faa-d6c6-4ee0-9a25-f71d77d4bf61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Loss: 82.1\n"
     ]
    }
   ],
   "source": [
    "# Use mean_squared_error function from sklearn to compute MSE\n",
    "sklearn_mse = mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print('Mean Squared Error Loss:', sklearn_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dc5ed4-9d93-43e4-820c-3fa8638c3aae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compute Mean Squared Error Loss with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22176eec-a041-4c76-af1d-460b62b35f26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error Loss: 82.1\n"
     ]
    }
   ],
   "source": [
    "# Create a custom function to compute MSE\n",
    "def mean_squared_err(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "numpy_mse = mean_squared_err(y_true, y_pred)\n",
    "\n",
    "print('Mean Squared Error Loss:', numpy_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54db0f1-0f32-4318-b09d-6ff6765de67a",
   "metadata": {},
   "source": [
    "### Comparison of the BCE computation results between PyTorch, Sci-kit Learn and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d9753f-4d67-4333-b4af-e768c2a2a455",
   "metadata": {},
   "source": [
    "Let's compare computed Mean Squared Error values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa2c1f2f-56fe-4df0-a916-98be4736ca73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_mse == sklearn_mse == numpy_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda87331-ec76-46bd-82f0-d594a7d24329",
   "metadata": {},
   "source": [
    "All three different method of computation of MSE provided the same result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
