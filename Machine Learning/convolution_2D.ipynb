{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d208c6e-3676-4f24-877f-cdce14445e88",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "**Disclaimer**: This notebook is lenghty, <u>navigate the links given below, if need be</u>.\n",
    "\n",
    "#### [Overview](#overview)\n",
    "#### [Computation](#computation)\n",
    "#### [Applications](#applications)\n",
    "#### [History](#history)\n",
    "#### [Landmarks of CNN in CV](#landmarks)\n",
    "\n",
    "**In the second cell of this notebook, we will create a custom function to compute a 3D convolution using Numpy library and FOR LOOPS to iterate over the input.**\n",
    "\n",
    "It's worth noting that **there are more efficient and optimized ways to implement convolutions** using libraries like <span style=\"font-size: 11pt; color: orange; font-weight: normal\">**NumPy**</span> or frameworks like <span style=\"font-size: 11pt; color: orange; font-weight: normal\">**TensorFlow**</span> or <span style=\"font-size: 11pt; color: orange; font-weight: normal\">**PyTorch**</span>. These libraries provide highly optimized functions and operations for convolutions, taking advantage of vectorized computations and parallel processing.\n",
    "***\n",
    "\n",
    "# Convolutions\n",
    "\n",
    "#### <a id=\"overview\"></a> Overview:\n",
    "\n",
    "**Convolutions** play a crucial role in various fields, especially in signal processing and Computer Vision (CV) and image processing tasks.Convolutions are typically used to extract useful features or apply filters to data.\n",
    "\n",
    "**Convolution** is a mathematical operation that combines two functions to produce a third function. It involves sliding one function, called the kernel or filter, over another function, called the input, while performing element-wise multiplication and summation. The result is a <u>transformed function that captures the interaction between the input and the kernel</u>.\n",
    "\n",
    "In the context of digital signal processing, Computer Vision or image analysis, the input and kernel are discrete sequences or matrices represented as arrays:\n",
    "\n",
    "```python\n",
    "# Input of size (2,2,3)\n",
    "input_array = np.array([[[2,2,3],\n",
    "                         [3,2,1]],\n",
    "                        [[1,3,1],\n",
    "                         [3,1,5]]])\n",
    "\n",
    "# Kernel of size (2,2,1)\n",
    "kernel_3D = np.array([[[  1],\n",
    "                       [- 1]],\n",
    "                      [[0.5],\n",
    "                       [0.5]]])\n",
    "\n",
    "# Resulting convolution:\n",
    "convolution = np.array([1, 2, 5])\n",
    "```\n",
    "#### <a id=\"computation\"></a> Computation of Convolution:\n",
    "\n",
    "The computation of convolution involves the following steps:\n",
    "\n",
    "1. Place the kernel on top of the input data, aligning it with a specific position (usually top left corner of an array).\n",
    "2. Perform element-wise multiplication between the kernel and the overlapped input values.\n",
    "3. Sum up the multiplied values to obtain a single value.\n",
    "    - Basically - compute dot product of values\n",
    "4. Slide the kernel to the next position and repeat the process until the entire input has been convolved.\n",
    "\n",
    "The resulting output from the convolution operation depends on the size of the input, the kernel, and the stride (the step size of the kernel movement). The output may have different dimensions than the input, depending if the **padding** was used (adding additional values around the input to preserve its size).\n",
    "\n",
    "If no padding was used, after applying convolutional kernel of size (3,3) to the input of size (9,9), the convolution's output size is (7,7)\n",
    "\n",
    "```python\n",
    "input_array.shape\n",
    ">>> (9,9)\n",
    "\n",
    "kernel.shape\n",
    ">>> (3,3)\n",
    "\n",
    "convolution.shape\n",
    ">>> (7,7)\n",
    "```\n",
    "\n",
    " \n",
    "Convolution is often used to apply filters or extract features by convolving the kernel with the input data. The kernel can be viewed as a small window that scans the input, and at each position, <span style=\"font-size: 11pt; color: green; font-weight: normal\">the **dot product** between the **kernel** and the corresponding **input values** is computed</span>.\n",
    "\n",
    "#### <a id=\"applications\"></a> Applications of Convolutions:\n",
    "\n",
    "1. **Signal Processing:** Convolutions are extensively used in signal processing tasks like noise removal, audio processing, and speech recognition. \n",
    "2. **Image Processing:** Convolutions are fundamental in image processing tasks, such as edge detection, blurring, sharpening, and feature extraction.\n",
    "3. **Computer Vision:** Convolutional Neural Networks (CNNs) leverage convolutions **extensively** for tasks like object recognition, image classification, and segmentation.\n",
    "4. **Natural Language Processing:** Convolutions are employed in text analysis, sentiment analysis, and language modeling to <u>capture local dependencies in sequences of words</u>.\n",
    "5. **Genomic Analysis:** Convolutions are utilized in bioinformatics to identify patterns in DNA sequences and analyze genetic data.\n",
    "\n",
    "#### <a id=\"history\"></a>History of Convolutions:\n",
    "\n",
    "The concept of convolutions dates back to the 18th century, with the work of mathematicians like **Jean-Baptiste Joseph Fourier** and **Sim√©on Denis Poisson**.   \n",
    "Fourier introduced the <u>Fourier Transform</u>, which can be seen as a generalization of the convolution operation.  \n",
    "Poisson made significant contributions to the theory of probability and introduced the Poisson distribution, which relates to convolutions in the context of summing random variables.\n",
    "\n",
    "In the early 20th century, **Karl Pearson**, a prominent statistician, utilized convolutions in his research on statistical distributions and the central limit theorem. He recognized the power of convolutions for combining probability distributions and analyzing their properties.\n",
    "\n",
    "#### <a id=\"landmarks\"></a>Landmarks in Convolutional Neural Networks (CNNs):\n",
    "\n",
    "<span style=\"font-size: 11pt; color: green; font-weight: normal\">**Convolutional Neural Networks (CNNs) have played a pivotal role in the advancement of deep learning and computer vision**</span>. Here are some important landmarks in the development of CNNs:\n",
    "\n",
    "1. **LeNet-5 (1998):** LeNet-5, developed by Yann LeCun et al., was one of the earliest CNN architectures used for handwritten digit recognition. It introduced the concept of convolutional layers and pooling layers.\n",
    "\n",
    "2. **AlexNet (2012):** AlexNet, developed by Alex Krizhevsky et al., won the ImageNet Large Scale Visual Recognition Challenge in 2012. It was a deep CNN architecture that popularized the use of ReLU activation functions and dropout regularization.\n",
    "\n",
    "3. **VGGNet (2014):** The VGGNet architecture, developed by the Visual Geometry Group (VGG) at the University of Oxford, was known for its simplicity and depth. It had 16 or 19 weight layers and was widely used as a baseline for image classification tasks.\n",
    "\n",
    "4. **GoogLeNet/Inception (2014):** The GoogLeNet architecture, also known as Inception, introduced the concept of the inception module, which used multiple parallel convolutional layers of different sizes to capture features at different scales efficiently.\n",
    "\n",
    "5. **ResNet (2015):** ResNet, developed by Kaiming He et al., introduced the concept of residual connections. This architecture enabled the training of extremely deep networks by mitigating the vanishing gradient problem.\n",
    "\n",
    "Convolutional neural networks and their advancements continue to push the boundaries of computer vision and have expanded into other domains, such as natural language processing and speech recognition, demonstrating the broad applicability of convolutions in deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60071ab-68ef-4933-96f5-89cd7b6b4e08",
   "metadata": {},
   "source": [
    "## <a id=\"examples\"></a> Computation of 2D convolution:\n",
    "This implementation follows the principles of sliding the kernel over the input, element-wise multiplication, and summation to compute the convolution.\n",
    "\n",
    "The implementation accounts for the dimensions of the input, kernel, and output array and the nested loops traverse the input and kernel to perform the necessary calculations. The use of `np.sum()` to calculate the convolution at each position aligns with the mathematical definition of convolutions.\n",
    "\n",
    "However, it's important to note that <u>this implementation assumes no padding and a stride of 1 in both the vertical and horizontal directions</u>. This means that the output size will be reduced compared to the input size due to the kernel's spatial dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afa9baf4-fbba-46f8-b8f4-ef129243f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0b97068-4333-4ceb-aa98-b56eb7507a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a generalized function to compute convolution\n",
    "\n",
    "def convolution(matrix_3D, kernel_3D):\n",
    "    \"\"\"\n",
    "    Perform 3D convolution on a given matrix using a kernel.\n",
    "\n",
    "    Args:\n",
    "        matrix_3D (ndarray): 3D input matrix of shape (layers, height, width).\n",
    "        kernel_3D (ndarray): 3D kernel matrix of shape (layers, kernel_height, kernel_width).\n",
    "\n",
    "    Returns:\n",
    "        ndarray: array containing the result of the convolution.\n",
    "    \"\"\"\n",
    "    # Initialize the result array with appropriate dimensions\n",
    "    my_convolution = np.zeros((matrix_3D.shape[0],\n",
    "                               matrix_3D.shape[1] - kernel_3D.shape[1] + 1,\n",
    "                               matrix_3D.shape[2] - kernel_3D.shape[2] + 1))\n",
    "\n",
    "    # Perform 3D convolution\n",
    "    for layer in range(matrix_3D.shape[0]):\n",
    "        for vertical_step in range(matrix_3D.shape[1] - kernel_3D.shape[1] + 1):\n",
    "            for horizontal_step in range(matrix_3D.shape[2] - kernel_3D.shape[2] + 1):\n",
    "                # Slice the input and perform element-wise multiplication with the kernel\n",
    "                sub_matrix = matrix_3D[layer,\n",
    "                                       vertical_step: vertical_step + kernel_3D.shape[1],\n",
    "                                       horizontal_step: horizontal_step + kernel_3D.shape[2]]\n",
    "                result = np.sum(sub_matrix * kernel_3D[layer])\n",
    "                my_convolution[layer, vertical_step, horizontal_step] = result\n",
    "\n",
    "    # Sum the convolutions across layers\n",
    "    my_convolution = np.sum(my_convolution, axis=0)\n",
    "\n",
    "    return my_convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50265c19-a3f2-41fd-bca9-7129156ac22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution: [[1. 2. 5.]]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "matrix_3D = np.array([[[2,2,3],\n",
    "                       [3,2,1]],\n",
    "                      [[1,3,1],\n",
    "                       [3,1,5]]])\n",
    "\n",
    "kernel_3D = np.array([[[  1],\n",
    "                       [- 1]],\n",
    "                      [[0.5],\n",
    "                       [0.5]]])\n",
    "\n",
    "result = convolution(matrix_3D, kernel_3D)\n",
    "print('Convolution:', result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
